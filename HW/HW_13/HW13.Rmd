```{r data download, results='hide', warning=FALSE, echo=FALSE}
library(tidyverse)
library(tsibble)
library(latex2exp)
library(dplyr)
library(magrittr)
library(patchwork)
library(lubridate)
library(feasts)
library(forecast)
library(sandwich)
library(fma)

if (!"fable" %in% rownames(installed.packages())) { install.packages("fable") }
library(fable)

if (!"car" %in% rownames(installed.packages())) { install.packages("car")}
library(car)
theme_set(theme_minimal())
```

```{r read csv into a dataframe}
isales <- read.csv('./data/iodine_sales.csv')
isales$date <- as.Date(isales$inv_date)
isales$total <- as.numeric(isales$total)

```


```{r get currency exchange rate}
library(yahoofinancer)
US_to_CA_rate <- currency_converter(
  from = "USD",
  to = "CAD",
  start = "2012-01-01",
  end = Sys.Date(),
  interval = "5d"
)

US_to_CA_rate <- US_to_CA_rate %>% 
    group_by(date = lubridate::floor_date(date, 'month')) %>%
    summarize(exchange_rate = mean(close))

US_to_CA_rate$date <- as.Date(US_to_CA_rate$date)
```


```{r convert all sales to CAD}
# 
isales_CAD <- isales %>%
  left_join(US_to_CA_rate, by = join_by(date)) %>% 
  mutate (total_CAD = total * exchange_rate) %>% 
  select(-inv_date, -currency, -total, -exchange_rate) 
```

```{r select big customers}
#get a list of customers, who bought more than 1M worth of product in 10 years
big_customers <- isales_CAD %>% group_by(cus_name)%>% summarise(rev = sum(total_CAD)) %>% filter(rev > 500000)

# Get sales for big customers only
sales_big <- isales_CAD %>% filter(cus_name %in% big_customers$cus_name)
```
## Total I-125 sales plot

```{r time series plot, results='hide', echo = FALSE, warning=FALSE}
monthly_sales <- isales_CAD %>% group_by(date) %>% summarize(sales = sum(total_CAD))
monthly_sales <- monthly_sales %>% as_tsibble(index = date)
#Plot the original series


ts_plot <- monthly_sales %>% 
  ggplot() + aes(x = date, y = sales/1000) + geom_line() + 
  labs(x = element_blank(), y = "I-125 sales, kCAD/month")+ ylim(0,900)

# Calculate the trend and de-trended series
trend <- ma(monthly_sales$sales, order = 3, centre = T)

monthly_sales <- mutate(monthly_sales, 
                   detrended = difference(sales, lag = 1))

#Generate dataframe for modeling
decomp_df <- cbind.data.frame(monthly_sales, trend)
names(decomp_df) = c("my_date", "value", "detrended", "trend")
decomp_df <- na.omit(decomp_df)

#Make plot for the TS
trnd_plt<- ggplot(data = decomp_df) + 
  geom_line(aes(x = my_date, y = trend/1000 )) + 
  labs(x = element_blank())+ ylim(0,900)

# Make plot for the de-trended series
detrended_plt <- ggplot(data = decomp_df) + aes(x = my_date, y = detrended ) + geom_line() + 
  labs(x = element_blank())

#Display plots
ts_plot/(trnd_plt|detrended_plt)
```
## Check for Stationary 

Use ACF/PACF and a unit root test to check if Retail Sales is stationary. If data is not stationary, difference the data, and apply the
test again until it becomes stationary? How many differences are needed to make data stationary?

```{r Check for Stationary}
value_p <- PP.test(decomp_df$value)
detrended_p <- PP.test(decomp_df$detrended)
```
Given strong trend in the data it is obvious that the original series is not stationary. De-trending with lag = 1 eliminates the trend. Results of Phillips-Perron test reflect these observations. The test fails to reject the hypothesis of non-stationarity for the original series (p-value = `r round (value_p$p.value, digits = 3)`) and de-seasoned series (p-value = `r round(deseasoned_p$p.value, digits = 3)`), but strongly rejects this hypothesis for the de-trended series with p-value = `r round(detrended_p$p.value, digits = 3)`)

## Model identification and estimation

```{r test train split}
train_ts <- monthly_sales %>% filter(date < as.Date("2021-01-01"))
test_ts <- monthly_sales %>% filter(date >= as.Date("2021-01-01"))
```


Use ACF/PACF to identify an appropriate SARIMA model. Estimate both select model and model chosen by ARIMA()

```{r Model identification}
decomp_filtered <- filter(decomp_df, my_date  < as.Date("2021-01-01") )

acf_plot <-  decomp_filtered$detrended %>%
  acf(plot = F,lag.max = 50) %>% autoplot() + xlim(1,50)

pacf_plot <- decomp_filtered$detrended %>%
  pacf(plot = F,lag.max = 50) %>% autoplot() + xlim(1,50)
acf_plot | pacf_plot
```



```{r Manual Model estimation}
model.manual<- arima(train_ts$sales, order = c(3, 1, 6))
model.manual
checkresiduals(model.manual)
```


```{r auto model estimation}
model.auto <- train_ts$sales %>% ts(frequency = 12) %>% auto.arima(d = 1, D = 0,
              max.p = 5, max.q = 5, max.P = 2, max.Q = 2, max.d = 2, max.D = 2,
              max.order = 10,
              start.p = 1, start.q = 1, start.P = 1, start.Q = 1,
  ic="bic", seasonal = TRUE, stepwise = FALSE, approximation = FALSE, trace = TRUE)
model.auto
```

```{r auto model estimation}
short_ts <- train_ts  %>% filter(date > as.Date("2019-01-01"))
model.short <- short_ts$sales %>% auto.arima(d = 1,
              max.p = 5, max.q = 5, max.d = 2,
              max.order = 10,
              start.p = 1, start.q = 1,
  ic="bic", seasonal = FALSE, stepwise = FALSE, approximation = FALSE, trace = FALSE)
model.short
```

ACF plot for de-seasoned and de-trended series contains one strongly significant lag = 1, same as PACF plot. Formally, this is typical for ARMA(1.1) process, however, there is also a chance that this is an artifact caused by the few lags at the end of the series that are affected by the pandemic abnormality. Having abnormally large values at the tail of the series might make short lags a lot more significant. This considerations aside, ACF and PACF plot suggest SARIMA(1.1.1)(0.1.0)[4] model. Estimating this model results in AIC = `r round(model.manual$aic, digits = 1)`.
Grid search with `auto.arima` function yields very similar result. The function find s the lowest AIC `r round(model.auto$aic, digits = 1)` for SARIMA(1.1.0)(0.1.0)[4]. The fact that MA component of ARIMA does not improve the model, despite the fact that PACF plot goes down abruptly after lag 1, supports the hypothesis that observed plots are just artifacts.
Repeating this grid search on the shortned training set that excludes the pandemic data results in a much lower AIC of `r round(model.short$aic, digits = 1)`.

## Model diagnostic 

Do residual diagnostic checking of both models. Are the residuals white noise? Use the Ljung-box test to check if the residuals are white noise.  

```{r diagnostic for manual model, echo=FALSE}
checkresiduals(model.manual, test=FALSE, plot = TRUE)
BLT.manual <- Box.test(as.ts(model.manual$residuals), lag = 1, type = "Ljung-Box")
```

```{r diagnostic for auto model, echo=FALSE}
checkresiduals(model.auto, test=FALSE, plot = TRUE)
BLT.auto <- Box.test(as.ts(model.auto$residuals), lag = 1, type = "Ljung-Box")
```

```{r diagnostic for short-set model, echo=FALSE}
checkresiduals(model.short, test=FALSE, plot = TRUE)
BLT.short <- Box.test(as.ts(model.short$residuals), lag = 1, type = "Ljung-Box")
```

Both manually estimated model as well as `auto.arima` result fail visual tests for model quality: in both cases residual distribution has a significant outlier and residual plots contain strong spikes. However, Ljung-Box Test fails to reject the null hypothesis with p-values `r round(BLT.manual$p.value, digits =2)` and `r round(BLT.auto$p.value, digits = 2)` respectively.
The model estimated on the shorter data does have all the charachteristics of good fit: normally distributed residuals with no pattern in acf plot and p-value `r round(BLT.short$p.value, digits =2)` on Ljung-Box Test, indicating no autocorrelation in residuals.



## Forcasting 

Use the both models to forecast the next 12 months and evaluate the forecast accuracy of these models.

```{r forcasting}
frcst_length = length(test_ts$sales)
frcst_manual <- forecast(model.manual, h=frcst_length)
frcst_auto <- forecast(model.auto, h=frcst_length)
frcst_short <- forecast(model.short, h=frcst_length)
```

```{r forcast plotting, echo = FALSE}
df_2frcst <- cbind.data.frame(test_ts, frcst_manual$mean, frcst_auto$mean, frcst_short$mean)
names(df_2frcst) <- c("my_date", "value", "detrended", "manual", "auto", "short")

ggplot(data = df_2frcst) + 
  geom_line(aes(x = my_date, y = value, color = "Observed data")) +
  geom_line(aes(x = my_date, y = manual, color = "Manual"), linewidth = 0.25) + 
  geom_line(aes(x = my_date, y = auto,  color = "Auto selected"), linewidth = 0.25) +
  geom_line(aes(x = my_date, y = short,  color = "Short"), linewidth = 0.25) +
  labs(x = element_blank(), y = 'Sales, CAD') + 
  ylim(0,700000)+
  # Legend colors
  scale_color_manual(name = "", values = c("Observed data" = "black", 
                                         "Manual" = "darkgreen",
                                         "Auto selected" = "blue",
                                         "Short" = "red" )) +
  # Legend text and position
  theme(legend.position=c(.25,.9),
        legend.text=element_text(size=12))
```

Both manually selected and auto-selected models make essentially the same predictions, both significantly overestimate the growth rate for the e-commerce sales. This is because the models were trained on the data that contained a large shock and they implicitly expect more of the similar shocks to come. The model that was trained on truncated data, on the other hand, captures the underlying market forces without compounding effect of once-in-a-lifetime anomaly. As a result, once the anomaly passes, this model predicts the actual observed data much better than the previous two.